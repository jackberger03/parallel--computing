#!/bin/bash
##ENVIRONMENT SETTINGS; CHANGE WITH CAUTION
#SBATCH --export=NONE            #Do not propagate environment
#SBATCH --get-user-env=L         #Replicate login environment
#
##NECESSARY JOB SPECIFICATIONS
#SBATCH --job-name=qsort_hypercube      #Set the job name to "qsort_hypercube"
#SBATCH --time=2:00:00           #Set the wall clock limit to 2hr
#SBATCH --nodes=2                #Request 2 nodes
#SBATCH --ntasks-per-node=48     #Request 48 tasks/cores per node
#SBATCH --mem=32G                #Request 32GB per node 
#SBATCH --output=qsort_output.%j       #Send stdout/err to "qsort_output.[jobID]"
#
##OPTIONAL JOB SPECIFICATIONS
##SBATCH --mail-type=ALL              #Send email on all job events
##SBATCH --mail-user=email_address    #Send all emails to email_address 
#
##First Executable Line
#
module load intel                # load Intel software stack
#
# Compile the program
echo "Compiling qsort_hypercube..."
mpiicpx -o qsort_hypercube.exe qsort_hypercube_completed.cpp

# Set parameters
n=20480000  # Local list size per process
type=0      # Initialization type

# Create output directory
mkdir -p results

# Run experiments for different process counts
echo "Running experiments..."
echo "n = $n, type = $type"
echo ""
echo "Process_Count,Total_List_Size,Execution_Time" > results/qsort_times.csv

# Run for p = 1, 2, 4, 8, 16, 32, 64
for p in 1 2 4 8 16 32 64
do
    if [ $p -le 96 ]; then  # Max 96 processes available (2 nodes * 48 cores)
        echo "Running with $p processes..."
        total_size=$((n * p))
        
        # Run the program and capture output
        output=$(mpirun -np $p ./qsort_hypercube.exe $n $type 2>&1)
        
        # Extract execution time
        exec_time=$(echo "$output" | grep "hypercube quicksort time" | awk '{print $NF}')
        
        # Check if sorted correctly
        if echo "$output" | grep -q "Congratulations"; then
            echo "p = $p: Success (time = $exec_time seconds)"
            echo "$p,$total_size,$exec_time" >> results/qsort_times.csv
        else
            echo "p = $p: FAILED - List not sorted correctly"
            echo "$p,$total_size,FAILED" >> results/qsort_times.csv
        fi
    else
        echo "Skipping p = $p (exceeds available cores)"
    fi
done

echo ""
echo "Experiments completed. Results saved to results/qsort_times.csv"

# Create Python script for plotting
cat > plot_results.py << 'EOF'
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# Read the results
df = pd.read_csv('results/qsort_times.csv')
df = df[df['Execution_Time'] != 'FAILED']
df['Execution_Time'] = pd.to_numeric(df['Execution_Time'])

# Calculate speedup and efficiency
# For speedup calculation, we need T1 for the appropriate problem size
# Speedup for p processes = T1(n*p) / Tp(n)
speedups = []
efficiencies = []
n = 20480000

for _, row in df.iterrows():
    p = row['Process_Count']
    tp = row['Execution_Time']
    
    # Find T1 for size n*p
    t1_row = df[(df['Process_Count'] == 1) & (df['Total_List_Size'] == n*p)]
    if not t1_row.empty:
        t1 = t1_row['Execution_Time'].values[0]
        speedup = t1 / tp
        efficiency = speedup / p
    else:
        # Estimate T1 if not available (extrapolation)
        # Use the fact that sorting is O(n log n)
        base_row = df[df['Process_Count'] == 1].iloc[0]
        base_size = base_row['Total_List_Size']
        base_time = base_row['Execution_Time']
        
        # Estimate time for size n*p
        factor = (n*p * np.log2(n*p)) / (base_size * np.log2(base_size))
        t1 = base_time * factor
        speedup = t1 / tp
        efficiency = speedup / p
    
    speedups.append(speedup)
    efficiencies.append(efficiency)

df['Speedup'] = speedups
df['Efficiency'] = efficiencies

# Create plots
fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))

# Plot 1: Execution Time
ax1.loglog(df['Process_Count'], df['Execution_Time'], 'bo-', label='Actual', markersize=8)
ax1.set_xlabel('Number of Processes (p)', fontsize=12)
ax1.set_ylabel('Execution Time (seconds)', fontsize=12)
ax1.set_title('Execution Time vs Number of Processes', fontsize=14)
ax1.grid(True, which="both", ls="-", alpha=0.2)
ax1.legend()

# Plot 2: Speedup
ax2.semilogx(df['Process_Count'], df['Speedup'], 'ro-', label='Actual Speedup', markersize=8)
ax2.semilogx(df['Process_Count'], df['Process_Count'], 'k--', label='Ideal Speedup', alpha=0.5)
ax2.set_xlabel('Number of Processes (p)', fontsize=12)
ax2.set_ylabel('Speedup', fontsize=12)
ax2.set_title('Speedup vs Number of Processes', fontsize=14)
ax2.grid(True, which="both", ls="-", alpha=0.2)
ax2.legend()

# Plot 3: Efficiency
ax3.semilogx(df['Process_Count'], df['Efficiency'], 'go-', label='Efficiency', markersize=8)
ax3.axhline(y=1.0, color='k', linestyle='--', alpha=0.5, label='Ideal Efficiency')
ax3.set_xlabel('Number of Processes (p)', fontsize=12)
ax3.set_ylabel('Efficiency', fontsize=12)
ax3.set_title('Efficiency vs Number of Processes', fontsize=14)
ax3.set_ylim(0, 1.2)
ax3.grid(True, which="both", ls="-", alpha=0.2)
ax3.legend()

plt.tight_layout()
plt.savefig('results/qsort_performance.png', dpi=300, bbox_inches='tight')
plt.savefig('results/qsort_performance.pdf', bbox_inches='tight')

# Print results table
print("\nPerformance Results:")
print("=" * 80)
print(f"{'Processes':>10} {'Total Size':>15} {'Time (s)':>12} {'Speedup':>10} {'Efficiency':>12}")
print("=" * 80)
for _, row in df.iterrows():
    print(f"{row['Process_Count']:>10d} {row['Total_List_Size']:>15d} {row['Execution_Time']:>12.6f} "
          f"{row['Speedup']:>10.2f} {row['Efficiency']:>12.3f}")
EOF

# Run the plotting script
module load python
python plot_results.py

echo ""
echo "Plots saved to results/qsort_performance.png and results/qsort_performance.pdf"